---
title:  "Hadoop이란?"
categories : BigData
tag : [BigData, Hadoop]
# 복수로 하려면 [Python, Blog]처럼 리스트 형태로 할당
toc : true
# toc순서는 markdown header(#) 기준 입니당
toc_sticky : true
toc_label : Content
toc_icon : "fas fa-book-open"
author_profile : false
use_math : true
---

**[Notification]** 
<br/>
<u>Update coming soon</u>
{: .notice--success}

# 1. Hadoop

## 1.1 What is Hadoop?

- Apache Hadoop은 Java 기반의 분산 컴퓨팅 플랫폼(Open Source)

- Fault Tolerance : Scalability(확장성)을 높이기 위해 장애를 발생할 수 있는 일로 간주

- 구성 요소
    - 분산 파일 시스템
    - 리소스 관리자와 스케줄러
    - 분산 데이터 처리 프레임 워크

### 1.1.1 분산 파일 시스템

- Hadoop은 스토리지로 선택할 수 있는 분산 파일 시스템 多
- 일반적으로 HDFS 사용
- HDFS(Hadoop Distributed File System)
    - Google File System 기반의 중복저장을 특징으로한 대규모 분산 파일 시스템
    - HDFS는 일반적인 파일 시스템을 가진 여러 노드를 묶어 하나의 분산 파일 시스템을 구축
    - HDFS의 가정
        1. Sequential Read 속도 多(풀스캐징 지원을 위함)
        2. 데이터는 연산 위치로 이동하는 것이 아닌, 저장된 곳에서 계산 수행(위치 정보를 충분히 교환)
        3. 노드 장애를 소프트웨어 레이어에서 극복
    - 데이터는 Block 형태로 저장
    - 각 Block은 투명하게 복제되어 여러 노드에 분산 
        - 위치투명성 : 위치를 알 필요없이 이름만으로 파일에 접근할 수 있는 특징(물리적 상황을 논리적 개념으로 추상화)
    - HDFS Architecture
    <br/>
    <br/>
    <br/>
        <p align="center"><img src = "https://github.com/SEUNGYEOPOH/SEUNGYEOPOH/assets/81912557/a3d1579f-6f10-4cd5-bb1e-5bc95fcd13d1" width = "50%" height = "50%" ></p>
        - Name node는 각 Data Node에서 전달하는 메타데이터와 Data Node 관리
        - 각 Data Node에서 File 이름, 크기, 권한 등 파일이 위치한 블록의 정보가 포함된 메타 데이터를 Name 노드에 전송
        - Data Node는 파일을 저장하는 역할(블록 단위) 
        - Check Point Node의 경우 장애 발생 직전 마지막 State를 보존하는 Check Point를 주기적으로 저장(장애 대비)

### 1.1.2 리소스 관리자와 스케줄러

- YARN(Yet Another Resource Negotiator)
    - 스케줄링과 리소스 관리로 데이터 지역성을 극대화하고 리소스 독점 제어
    - 교체 가능한 스케줄링 시스템 지원
    - 클러스터의 리소스를 컨테이너로 분할
        - 여기서 클러스터는 연결된 컴퓨터들의 군집을 의미하며, 이 컴퓨터들의 자원을 컨테이너 별로 나누어 저장한다는 의미
        - Ex. 1번 컨테이너는 CPU, 2번 컨테이너는 Memory, 3번 컨테이너는 GPU 등
    - YARN은 이 컨테이너를 모니터링 하며, 할당된 리소스 기능 초과하지 않도록 관리
    - Data 지역성 역시 리소스로 제공 (가까운 위치일수록 비용절감)
- Hadoop Architecture
    <br/>
    <br/>
    <p align="center"><img src = "https://github.com/SEUNGYEOPOH/SEUNGYEOPOH/assets/81912557/a4ff7e20-2d3f-417d-8e28-a1bdb7e7d0eb" width = "60%" height = "60%" ></p>


### 1.1.3 분산 데이터 처리 프레임워크

- Map Reduce
    - 대용량 데이터를 병렬처리하기 위한 S/W 프레임워크 (google)
    - HDFS의 데이터 지역성과 YARN의 스케줄 및 리소스 관리로 효율적인 수행 가능
    - 단계
        1. map
            - Input Data는 클러스터에서 병렬 처리
            - mapper function은 Raw Data를 Key : Value로 변환
        2. shuffle
            - mapper fuction에서 변환된 Data를 Key를 기준으로 정렬
            - bucket(partition)으로 셔플링 
                - bucket or partition은 key를 기준으로 군집화 후 같은 범위에 속하는 Data의 집합(단위)
                -  동일한 key는 같은 bucket(partition)
        3. reduce
            - 모든 키의 값을 처리 후 결과를 HDFS or 저장소 저장
            - 같은 키를 가진 value를 더한다는 의미
    - Map-Reduce Process
        <br/>
        <br/>
    <p align="center"><img src = "https://github.com/SEUNGYEOPOH/SEUNGYEOPOH/assets/81912557/13682b04-9948-4fc4-b9f9-a10d747d732c" width = "70%" height = "70%" ></p>
    


